{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4_Happy_or_Sad",
      "provenance": [],
      "authorship_tag": "ABX9TyPN8eh15I71Q5qjYHuAbqs4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P06TSH4zKHYg"
      },
      "source": [
        "source: https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W4/assignment/C1_W4_Assignment.ipynb#scrollTo=3NFuMFYXtwsT\n",
        "\n",
        "I added some codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dBP7BRPKpX2",
        "outputId": "a4eeb904-6df8-4f9f-8668-d3f34d3699fd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "!gdown --id 1NvV6VhmrfU8JDZNoEbwJxwx_6dhyN5bf \n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"./happy-or-sad.zip\", 'r')\n",
        "zip_ref.extractall(\"./h-or-s\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NvV6VhmrfU8JDZNoEbwJxwx_6dhyN5bf\n",
            "To: /content/happy-or-sad.zip\n",
            "\r0.00B [00:00, ?B/s]\r2.67MB [00:00, 82.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22uh58RfKwbH"
      },
      "source": [
        "# Directory with our training happy pictures\n",
        "train_happy_dir = os.path.join('./h-or-s/happy')\n",
        "\n",
        "# Directory with our training sad pictures\n",
        "train_sad_dir = os.path.join('./h-or-s/sad')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK7hLIQ2Oo6n",
        "outputId": "b5f2a922-e895-45a3-cee3-d1a4afbbb317"
      },
      "source": [
        "train_happy_names = os.listdir(train_happy_dir)\n",
        "print(train_happy_names[:10])\n",
        "\n",
        "train_sad_names = os.listdir(train_sad_dir)\n",
        "print(train_sad_names[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy1-02.png', 'happy1-05.png', 'happy2-16.png', 'happy1-19.png', 'happy2-06.png', 'happy2-17.png', 'happy1-15.png', 'happy1-18.png', 'happy1-07.png', 'happy1-00.png']\n",
            "['sad2-19.png', 'sad2-12.png', 'sad1-11.png', 'sad1-02.png', 'sad2-11.png', 'sad1-00.png', 'sad1-07.png', 'sad1-10.png', 'sad2-01.png', 'sad1-12.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT-yMhxnO_6W",
        "outputId": "634f702e-ad4b-4ba5-ca20-6d15c7b8002f"
      },
      "source": [
        "print('total training happy images:', len(os.listdir(train_happy_dir)))\n",
        "print('total training sad images:', len(os.listdir(train_sad_dir)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training happy images: 40\n",
            "total training sad images: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NcAWmVUPQ8Nu",
        "outputId": "93b2c904-0459-4615-90e4-967d05aa95ec"
      },
      "source": [
        "train_happy_names[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'happy1-02.png'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqogRpYqwkCg"
      },
      "source": [
        "DESIRED_ACCURACY = 0.999\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>=DESIRED_ACCURACY):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANcue_bRNVj"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8oEbnZPSyQb"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_jwt2mS26I"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k_OVMetS4YA"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3B53nBOS_H6",
        "outputId": "0da8fe8e-cbfc-4b9e-c592-6ed16825b09d"
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './h-or-s/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        #batch_size=25,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTLNz8MTTI3x",
        "outputId": "ad4f1004-9a4e-46d6-f6cb-511cbe05a808"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      #steps_per_epoch=5,  \n",
        "      epochs=8,\n",
        "      verbose=1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "3/3 [==============================] - 2s 531ms/step - loss: 2.7228e-07 - accuracy: 1.0000\n",
            "Epoch 2/8\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 2.5176e-07 - accuracy: 1.0000\n",
            "Epoch 3/8\n",
            "3/3 [==============================] - 2s 522ms/step - loss: 2.2308e-07 - accuracy: 1.0000\n",
            "Epoch 4/8\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 1.7600e-07 - accuracy: 1.0000\n",
            "Epoch 5/8\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 1.5385e-07 - accuracy: 1.0000\n",
            "Epoch 6/8\n",
            "3/3 [==============================] - 2s 529ms/step - loss: 1.4001e-07 - accuracy: 1.0000\n",
            "Epoch 7/8\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 1.1457e-07 - accuracy: 1.0000\n",
            "Epoch 8/8\n",
            "3/3 [==============================] - 2s 719ms/step - loss: 9.8691e-08 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FAvuOsITNF6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}